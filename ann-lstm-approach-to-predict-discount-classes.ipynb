{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d96eb4dd1cb16e1d04b48a26d6bffa8b0e0aac2"
   },
   "source": [
    "<font size=\"20\">Discount Prediction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e86bb06b8be3861460060e9beca27d37e8cfafbe"
   },
   "source": [
    "The objective of this \"Discount Prediction\" Competition was to build a model to Predict Medical Wholesales Discount to their customers. In this notebook, we will walk through a complete machine learning solution, try out two deep learning models, select a model and , inspect the outputs of the model and draw conclusions. We would like to thank everyone for this hackathon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b15c4242ef5eab0176483c2d262610716a26916"
   },
   "source": [
    "<h1>Importing the Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b9d91f358a8cad0a5681c0de601005fae513dc1a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd #Data Analysis\n",
    "import numpy as np #Linear Algebra\n",
    "import seaborn as sns #Data Visualization\n",
    "import matplotlib.pyplot as plt #Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1ab8b102514788aff0fa37a37f22c27df669fb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['remove', 'discount-prediction']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60963ac9c166fd8a94082d8fd025bc03ca9d2db6"
   },
   "source": [
    "<h1>Importing the datasets</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e54c1755c0a748b84ef67cab2a6e3bf4af6c681a"
   },
   "outputs": [],
   "source": [
    "#This is the Product_sales_train_and_test dataset but without the \"[]\" in the Customer Basket.\n",
    "df1=pd.read_csv(\"../input/remove/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "2be3a39d9ff439268abcee3c87c2ba780bcf73dd"
   },
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"../input/discount-prediction/Train.csv\")\n",
    "df3=pd.read_csv(\"../input/discount-prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b4415180cc3da540cf79df87455819478752260e"
   },
   "outputs": [],
   "source": [
    "df1.fillna(float(0.0),inplace=True)\n",
    "df2.fillna(float(0.0),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1438a604b74489023d612cdf7ffb52faa7602647"
   },
   "source": [
    "Since to differentiate the Customer Basket is an NLP Problem we will be using CountVectoriser. It converts a collection of text documents to a matrix of token counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3bc064c1d2ad45a3647fe88ae7b766c12d0ec0c9"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv1 = CountVectorizer(max_features=500)\n",
    "y = cv1.fit_transform(df1[\"Customer_Basket\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c6f7cd0808a08c6f0b30b75f5039237695eb10c1"
   },
   "outputs": [],
   "source": [
    "thirty= list(y)\n",
    "thirty1=pd.DataFrame(thirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "51e1932e5471133b1b94b78eddfcff65276d59ab"
   },
   "outputs": [],
   "source": [
    "final=pd.concat([df1,thirty1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "441393c5c6a7bbe489710edcff366a275fb5b6db"
   },
   "outputs": [],
   "source": [
    "df2=df2[df2[\"BillNo\"]!=float(0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bf73c4a22608a6d604900d49a6388c8ad7f17deb"
   },
   "outputs": [],
   "source": [
    "finaltrain=pd.merge(final,df2,on=\"BillNo\",how=\"inner\")\n",
    "finaltest=pd.merge(final,df3,on=\"BillNo\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7f40eb35b12c3bbf5a558552be6d083283564dfc"
   },
   "outputs": [],
   "source": [
    "finaltrain.drop([\"BillNo\",\"Customer_Basket\",\"Customer\",\"Date\"],axis=1,inplace=True)\n",
    "finaltest.drop([\"BillNo\",\"Customer_Basket\",\"Customer\",\"Date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "83c80ae43eeb038854c4adb55ce64b08d0863160"
   },
   "outputs": [],
   "source": [
    "X=finaltrain.drop([\"Discount 5%\",\"Discount 12%\",\"Discount 18%\",\"Discount 28%\"],axis=1)\n",
    "y=finaltrain[[\"Discount 5%\",\"Discount 12%\",\"Discount 18%\",\"Discount 28%\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "484bea530606db6018fe1fcec82fb24f4eb9ddf9"
   },
   "outputs": [],
   "source": [
    "X1, y2 = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "056c095509fba957ed6dfc17ab52f26ea7d47a8f"
   },
   "outputs": [],
   "source": [
    "var = np.reshape(X1, (X1.shape[0], X1.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58a80e4ba09fa81f005ef33df210e7ce412f6d0f"
   },
   "source": [
    "<h1>Modeling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "2ba60056bea5131d4faa274673feffddc7a6ce2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48b50b016da78e1270e572c0529b4f015a377d91"
   },
   "source": [
    "<h1>1. Artificial Neural Networks (ANN)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "5565991bd01406ee1b82a7df27bd54a40505e215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12200/12200 [==============================] - 3s 276us/step - loss: 0.7882 - acc: 0.7725\n",
      "Epoch 2/50\n",
      "12200/12200 [==============================] - 2s 202us/step - loss: 0.7212 - acc: 0.7730\n",
      "Epoch 3/50\n",
      "12200/12200 [==============================] - 2s 199us/step - loss: 0.7119 - acc: 0.7730\n",
      "Epoch 4/50\n",
      "12200/12200 [==============================] - 2s 198us/step - loss: 0.7067 - acc: 0.7730\n",
      "Epoch 5/50\n",
      "12200/12200 [==============================] - 3s 205us/step - loss: 0.6965 - acc: 0.7730\n",
      "Epoch 6/50\n",
      "12200/12200 [==============================] - 3s 207us/step - loss: 0.6824 - acc: 0.7730\n",
      "Epoch 7/50\n",
      "12200/12200 [==============================] - 3s 212us/step - loss: 0.6523 - acc: 0.7732\n",
      "Epoch 8/50\n",
      "12200/12200 [==============================] - 2s 200us/step - loss: 0.6016 - acc: 0.7756\n",
      "Epoch 9/50\n",
      "12200/12200 [==============================] - 2s 189us/step - loss: 0.5417 - acc: 0.7854\n",
      "Epoch 10/50\n",
      "12200/12200 [==============================] - 2s 191us/step - loss: 0.4839 - acc: 0.8030\n",
      "Epoch 11/50\n",
      "12200/12200 [==============================] - 2s 197us/step - loss: 0.4327 - acc: 0.8211\n",
      "Epoch 12/50\n",
      "12200/12200 [==============================] - 2s 205us/step - loss: 0.3989 - acc: 0.8386\n",
      "Epoch 13/50\n",
      "12200/12200 [==============================] - 2s 199us/step - loss: 0.3706 - acc: 0.8516\n",
      "Epoch 14/50\n",
      "12200/12200 [==============================] - 2s 201us/step - loss: 0.3507 - acc: 0.8625\n",
      "Epoch 15/50\n",
      "12200/12200 [==============================] - 2s 202us/step - loss: 0.3266 - acc: 0.8720\n",
      "Epoch 16/50\n",
      "12200/12200 [==============================] - 2s 196us/step - loss: 0.3180 - acc: 0.8770\n",
      "Epoch 17/50\n",
      "12200/12200 [==============================] - 3s 214us/step - loss: 0.3097 - acc: 0.8816\n",
      "Epoch 18/50\n",
      "12200/12200 [==============================] - 3s 210us/step - loss: 0.2926 - acc: 0.8875\n",
      "Epoch 19/50\n",
      "12200/12200 [==============================] - 2s 195us/step - loss: 0.2921 - acc: 0.8855\n",
      "Epoch 20/50\n",
      "12200/12200 [==============================] - 2s 204us/step - loss: 0.2809 - acc: 0.8927\n",
      "Epoch 21/50\n",
      "12200/12200 [==============================] - 2s 200us/step - loss: 0.2803 - acc: 0.8909\n",
      "Epoch 22/50\n",
      "12200/12200 [==============================] - 2s 195us/step - loss: 0.2699 - acc: 0.8947\n",
      "Epoch 23/50\n",
      "12200/12200 [==============================] - 2s 196us/step - loss: 0.2589 - acc: 0.8981\n",
      "Epoch 24/50\n",
      "12200/12200 [==============================] - 2s 198us/step - loss: 0.2522 - acc: 0.9013\n",
      "Epoch 25/50\n",
      "12200/12200 [==============================] - 2s 196us/step - loss: 0.2446 - acc: 0.9042\n",
      "Epoch 26/50\n",
      "12200/12200 [==============================] - 2s 199us/step - loss: 0.2390 - acc: 0.9087\n",
      "Epoch 27/50\n",
      "12200/12200 [==============================] - 2s 199us/step - loss: 0.2387 - acc: 0.9051\n",
      "Epoch 28/50\n",
      "12200/12200 [==============================] - 2s 200us/step - loss: 0.2326 - acc: 0.9092\n",
      "Epoch 29/50\n",
      "12200/12200 [==============================] - 2s 197us/step - loss: 0.2312 - acc: 0.9116\n",
      "Epoch 30/50\n",
      "12200/12200 [==============================] - 2s 200us/step - loss: 0.2195 - acc: 0.9188\n",
      "Epoch 31/50\n",
      "12200/12200 [==============================] - 2s 201us/step - loss: 0.2119 - acc: 0.9178\n",
      "Epoch 32/50\n",
      "12200/12200 [==============================] - 2s 195us/step - loss: 0.2111 - acc: 0.9178\n",
      "Epoch 33/50\n",
      "12200/12200 [==============================] - 2s 192us/step - loss: 0.2131 - acc: 0.9211\n",
      "Epoch 34/50\n",
      "12200/12200 [==============================] - 2s 194us/step - loss: 0.2037 - acc: 0.9225\n",
      "Epoch 35/50\n",
      "12200/12200 [==============================] - 2s 199us/step - loss: 0.1970 - acc: 0.9244\n",
      "Epoch 36/50\n",
      "12200/12200 [==============================] - 2s 200us/step - loss: 0.1925 - acc: 0.9273\n",
      "Epoch 37/50\n",
      "12200/12200 [==============================] - 2s 197us/step - loss: 0.1942 - acc: 0.9261\n",
      "Epoch 38/50\n",
      "12200/12200 [==============================] - 3s 206us/step - loss: 0.1894 - acc: 0.9293\n",
      "Epoch 39/50\n",
      "12200/12200 [==============================] - 2s 201us/step - loss: 0.1950 - acc: 0.9259\n",
      "Epoch 40/50\n",
      "12200/12200 [==============================] - 2s 198us/step - loss: 0.1816 - acc: 0.9320\n",
      "Epoch 41/50\n",
      "12200/12200 [==============================] - 3s 208us/step - loss: 0.1817 - acc: 0.9321\n",
      "Epoch 42/50\n",
      "12200/12200 [==============================] - 2s 204us/step - loss: 0.1744 - acc: 0.9334\n",
      "Epoch 43/50\n",
      "12200/12200 [==============================] - 3s 220us/step - loss: 0.1762 - acc: 0.9328\n",
      "Epoch 44/50\n",
      "12200/12200 [==============================] - 3s 206us/step - loss: 0.1805 - acc: 0.9330\n",
      "Epoch 45/50\n",
      "12200/12200 [==============================] - 2s 204us/step - loss: 0.1743 - acc: 0.9343\n",
      "Epoch 46/50\n",
      "12200/12200 [==============================] - 2s 202us/step - loss: 0.1714 - acc: 0.9356\n",
      "Epoch 47/50\n",
      "12200/12200 [==============================] - 3s 213us/step - loss: 0.1710 - acc: 0.9343\n",
      "Epoch 48/50\n",
      "12200/12200 [==============================] - 3s 216us/step - loss: 0.1671 - acc: 0.9369\n",
      "Epoch 49/50\n",
      "12200/12200 [==============================] - 2s 202us/step - loss: 0.1627 - acc: 0.9389\n",
      "Epoch 50/50\n",
      "12200/12200 [==============================] - 3s 208us/step - loss: 0.1547 - acc: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62aed43e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu', input_dim = 500))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units =32 , kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Dense(units =16 , kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X, y, batch_size = 10, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4c7e688432f00445ac1acd9e882e8ecc56710dff"
   },
   "outputs": [],
   "source": [
    "annpredictions=classifier.predict(finaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2b91ae19e9075bae8a5748d38e7355964e0d1df1"
   },
   "outputs": [],
   "source": [
    "discountann=list(annpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "60a07a811f118de9d17ff9611c9a8accb28f6512"
   },
   "outputs": [],
   "source": [
    "abbasann=pd.DataFrame(discountann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "459ca21f2667eb29e221a5c624847ff47c701b18"
   },
   "outputs": [],
   "source": [
    "abbasann=(abbasann> 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0081905ffb282e2e77934513b96d51d6422f8b19"
   },
   "source": [
    "<h1>2. LSTM</h1><br>\n",
    "First we used ANN but the results were poor and as seen ini our previous kernel we could not see any Customer getting preference for Discounts. Therefore we tried to capture the pattern of discounts been given using an LSTM approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7bd46ee0a928b2021b514ed3a6333232106f764"
   },
   "source": [
    "Importing the necessary libraries for an LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "219d4fc164f9176c1072d571489c387cf7f59a84"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "48069c92dc0322d51d7952605ad136dce753b26d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "12200/12200 [==============================] - 567s 46ms/step - loss: 0.7452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62986a4748>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (var.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(var, y2, epochs = 1, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1130557f2bf9fa5ca10156129f9baa7f7bafa76b"
   },
   "source": [
    "We have purposely set the epoch time to 1 as it takes a long time for the kernel to commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "91de555526640313a438eb23df99b132a91308fd"
   },
   "outputs": [],
   "source": [
    "finaltest1=np.array(finaltest)\n",
    "baas=np.reshape(finaltest1, (finaltest1.shape[0], finaltest1.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "0aacf3e49a992822c614a9b50e5d7208296edb44"
   },
   "outputs": [],
   "source": [
    "discountclass=regressor.predict(baas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "aff6230c7436dbbbbd2bfb053ef319d9a34c15df"
   },
   "outputs": [],
   "source": [
    "discountbaas=list(discountclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "23777b7de36f91189ecc140dae1bc23f8a276a17"
   },
   "outputs": [],
   "source": [
    "abbas=pd.DataFrame(discountbaas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "7ee779796d2849423f2f42c9d880334c18898264"
   },
   "outputs": [],
   "source": [
    "abbas= (abbas > 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9907b74933373aa00e45e7db7a77a714cadd6a16"
   },
   "source": [
    "<h1>Result</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "818923d3b83c41dbca4d3a23490a18c6facadf6c"
   },
   "source": [
    "At the end we were able to discern that an <b>LSTM</b> gave us the best result. One major change that we noticed was that the Bill Numbers were change from ZA's to A's from July 1st, 2017 and that in this transition the majority of Discounts also drastically changed from 28% to 12%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
